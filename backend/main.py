# backend/main.py

import os
import json
from fastapi import FastAPI, Query, Body, HTTPException
from fastapi.responses import StreamingResponse, FileResponse
from fastapi.middleware.cors import CORSMiddleware
from langchain_google_genai import ChatGoogleGenerativeAI
from graph_engine import app as chain
from engine import BlackPhysicsEngine
from dotenv import load_dotenv
from graph_engine import MASTER_ASSETS
from fastapi.staticfiles import StaticFiles

app = FastAPI()
load_dotenv()

app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

engine = BlackPhysicsEngine()

@app.post("/api/mission/stream/{mission_id}")
async def stream_mission(
    mission_id: str, 
    key: str = Query(None),
    payload: dict = Body(...)
):

    current_status = payload.get("status")
    lang = payload.get("language", "ja") 
    is_jp = (lang == "ja")

    if current_status == "FAILED":
        msg = "ã€APIåˆ¶é™ã€‘APIãƒªã‚½ãƒ¼ã‚¹ãŒå°½ãã¾ã—ãŸã€‚12:00 AM PT ã«ãƒªã‚»ãƒƒãƒˆäºˆå®šã€‚æ˜æ—¥ã¾ãŸãŠè©¦ã—ãã ã•ã„ã€‚" if is_jp else "[API LIMIT] API resources exhausted. Reset scheduled for 12:00 AM PT. Please try again tomorrow."
        raise HTTPException(status_code=429, detail=msg)

    api_key = key or os.getenv("GOOGLE_API_KEY")
    if not api_key or len(api_key) < 10:
        raise HTTPException(
            status_code=401, 
            detail="Unauthorized access. API Key is missing or invalid."
        )

    # LLM definition (Optimized for chemical structural modification)
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash", 
        google_api_key=api_key,
        temperature=0.2, 
        max_output_tokens=5500,
        streaming=True
    )

    # payloadã®ä¸­èº«ã‚’ç¢ºå®š
    m_assets = MASTER_ASSETS.get(mission_id, {})
    scaffolds = m_assets.get("scaffolds", [])
    selected_id = payload.get("selected_scaffold_id", "")
    
    # --- base_scaffold_data ã®ç¢ºå®šãƒ­ã‚¸ãƒƒã‚¯ ---
    # åˆå›ï¼ˆiteration 0ï¼‰ã¾ãŸã¯ãƒ‡ãƒ¼ã‚¿ãŒæ¬ è½ã—ã¦ã„ã‚‹å ´åˆã®ã¿ã€MASTER_ASSETSã‹ã‚‰å¼•ãå½“ã¦ã‚‹
    if payload.get("iteration", 0) == 0 or not payload.get("base_scaffold_data"):
        m_assets = MASTER_ASSETS.get(mission_id, {})
        scaffolds = m_assets.get("scaffolds", [])
        selected_id = payload.get("selected_scaffold_id", "")
        
        # IDãŒä¸€è‡´ã™ã‚‹ã‚‚ã®ã‚’å¼•ãå½“ã¦ã‚‹
        base_data = next((s for s in scaffolds if s["id"] == selected_id), {})
        payload["base_scaffold_data"] = base_data
    # iteration > 0 ã®å ´åˆã¯ã€ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‹ã‚‰é€ã‚‰ã‚Œã¦ããŸ base_scaffold_data ã‚’ãã®ã¾ã¾ç¶­æŒã™ã‚‹

    # State Mapping for "Black-Hole Discovery" Architecture
    # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã‹ã‚‰ã®æ–°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å„ªå…ˆçš„ã«ãƒãƒƒãƒ”ãƒ³ã‚°
    state_input = {
        "mission_id": mission_id,
        "language": lang,
        "philosophy": payload.get("philosophy", "STANDARD").upper(),
        "scaffold_id": payload.get("selected_scaffold_id", ""),
        "base_scaffold_data": payload.get("base_scaffold_data", {}),
        "entropy_level": float(payload.get("entropy_level", 0.1)),
        
        "iteration": payload.get("iteration", 0),
        "status": "RUNNING", # ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸã‚‰RUNNINGã§å†é–‹
        "physics_fail_count": payload.get("physics_fail_count", 0),
        "current_smiles": payload.get("current_smiles", ""),
        "candidates": payload.get("candidates", []),
        "metrics_results": payload.get("metrics_results", []),
        "transformation_metrics": payload.get("transformation_metrics", {}),
        
        "scientific_report": payload.get("scientific_report", ""),
        "next_instruction": "",
        "dialogue": payload.get("dialogue", []),
        # "three_d_data": payload.get("three_d_data", {}),
        "distilled_lesson": payload.get("distilled_lesson", "")
    }

    # å†…éƒ¨ãƒ«ãƒ¼ãƒ—ã®æ•‘æ¸ˆå‡¦ç½®: physics_fail_count=3ã§NEXTãŒé¸æŠã•ã‚ŒãŸå ´åˆã€ã‚«ã‚¦ãƒ³ãƒˆã‚’0ã«æˆ»ã—physics_nodeã§å³åº§ã«FAILEDã«ãªã‚‹ã®ã‚’é˜²æ­¢ã€‚
    # if state_input["physics_fail_count"] >= 3:
        # state_input["physics_fail_count"] = 0

    async def event_generator():
        current_running_state = state_input.copy()
        config = {"configurable": {"llm": llm, "engine": engine, "thread_id": mission_id, "language": lang}}

        # ãƒ‡ãƒãƒƒã‚°ç”¨
        if state_input["iteration"] > 0:
            print(f"DEBUG: [RE-STARTING FROM CHECKPOINT] Mission: {mission_id}, Iteration: {state_input['iteration']}")

        try:
            # iteration > 0 ã®å ´åˆã®å…¥åŠ›ã‚’æ•´ç†
            initial_input = None if state_input["iteration"] > 0 else state_input

            # ğŸš€ 
            yield f"data: {json.dumps({'type': 'node_start', 'node': 'vermouth'}, ensure_ascii=False)}\n\n"

            async for event in chain.astream(initial_input, config=config, stream_mode="updates"):
                print(f"DEBUG: Event received from chain: {event}") # for debagging
                for node_name, output in event.items():
                    if node_name.startswith("__"): continue

                    # æ—¢å­˜ã®Stateã‚’æ›´æ–°
                    current_running_state.update(output)

                    # ã‚¾ãƒ³ãƒ“ãƒ«ãƒ¼ãƒ—åœæ­¢
                    # is_failed = current_running_state.get("status") == "FAILED"

                    # scientific_reportã‹ã‚‰ã‚·ã‚§ãƒªãƒ¼ã®ã‚»ãƒªãƒ•ã«å«ã‚ã‚‹éƒ¨åˆ†ã‚’æŠ½å‡º
                    if node_name == "sherry":
                        report = output.get("scientific_report", "")
                        metrics = output.get("metrics_results", [])
                        best_candidate = metrics[0] if metrics else {}
                        descriptors = best_candidate.get("descriptors", {})

                        # 2. Center Paneç”¨ã®ä¼šè©±æ–‡ã‚’æŠ½å‡º
                        import re
                        display_text = ""
                        if report and report != "Analysis failed.":
                            # æœ€åˆã®ã€Œ\n\nã€ã¾ãŸã¯ã€Œã€‚ ã€ã§åŒºåˆ‡ã£ã¦ã€äººé–“ã‚‰ã—ã„çµè«–ã ã‘ã‚’æŠ½å‡º
                            # data_separator_pattern = re.split(r'\n\n|(?<=ã€‚)\s', report)
                            paragraphs = report.split("\n\n")
                            display_text = paragraphs[0].strip()
                        
                        # 3. ã‚¹ãƒ†ãƒ¼ãƒˆã®æ•´åˆæ€§ã¨å±¥æ­´ã®é–ã‚’ç¶­æŒ
                        if "dialogue" in output:
                            history = list(current_running_state.get("dialogue", []))
                            # new_responses = []
                            for msg in output["dialogue"]:
                                # ã‚·ã‚§ãƒªãƒ¼ã®è©³ç´°è¦‹è§£ãŒã‚ã‚‹å ´åˆã€ã“ã“ã§ã®ã¿åæ˜ 
                                if msg["agent"] == "Sherry":
                                    msg["text"] = display_text
                                
                                # é‡è¤‡æ’é™¤ã—ã¤ã¤è¿½åŠ 
                                if not any(h["agent"] == msg["agent"] and h["text"] == msg["text"] for h in history[-3:]):
                                    history.append(msg)
                            
                            # current_running_state ã¨ output ã®ä¸¡æ–¹ã«æœ€æ–°ã®æ­´å²ã‚’åæ˜ 
                            current_running_state["dialogue"] = history
                            output["dialogue"] = history

                            # ä¸‡ãŒä¸€ã€dialogueã«SherryãŒã„ãªãã¦reportãŒã‚ã‚‹å ´åˆã®æ•‘æ¸ˆ
                            if not any(m["agent"] == "Sherry" for m in output["dialogue"]) and display_text:
                                output["dialogue"].insert(0, {"agent": "Sherry", "text": display_text})     

                        # 4. ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ãŒç›´æ¥å‚ç…§ã§ãã‚‹ã‚­ãƒ¼ã‚’è¿½åŠ 
                        # ã“ã‚Œã«ã‚ˆã‚Šã€ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰å´ã§ 'output.display_metrics' ã‚’è¦‹ã‚‹ã ã‘ã§è¡¨ç¤ºå¯èƒ½ã«ãªã‚‹
                        output["display_metrics"] = descriptors
                        output["full_report"] = report
                        # output["current_sdf"] = best_candidate.get("sdf", "")

                        mut_val = best_candidate.get("mutation_score", 0) * 100
                        output["formatted_analysis"] = (
                            f"MUTATION_SCORE:{mut_val}% / MW:{descriptors.get('mw')} / PSA:{descriptors.get('psa')} / RINGS:{descriptors.get('rings')}"
                        )  

                    # ãƒ‡ãƒãƒƒã‚°ç”¨ã«ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
                    # print(f"DEBUG: [Sherry Node Trace] 3D Data Presence: {'three_d_data' in current_running_state}")
                    print(f"DEBUG: [Sherry Node Trace] Metrics Presence: {'metrics_results' in current_running_state}")
                    
                    response_payload = {
                        "type": "node_update",
                        "node": node_name,
                        "output": output,
                        "full_state": {**current_running_state}
                    }
                    yield f"data: {json.dumps(response_payload, ensure_ascii=False, default=str)}\n\n"
 
                    # ğŸš€
                    next_node = None
                    if current_running_state.get("status") == "FAILED":
                        print(f"DEBUG: Mission FAILED at {node_name}. Terminating stream immediately.")
                        break

                    if node_name == "vermouth":
                        if current_running_state.get("philosophy") == "SERENDIPITY":
                            next_node = "Mutate Engine" 
                        else:
                            next_node = "Physics Engine" 

                    elif node_name == "mutate":
                        next_node = "Physics Engine"

                    elif node_name == "physics":
                        next_node = "Sherry"
                        
                    if next_node:
                        yield f"data: {json.dumps({'type': 'node_start', 'node': next_node})}\n\n"

                # ãƒ–ãƒ©ã‚¦ã‚¶ã®ãƒãƒƒãƒ•ã‚¡ã‚’ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ã•ã›ã‚‹ãŸã‚ã®ãƒ€ãƒŸãƒ¼ã‚’é€ä¿¡
                yield "data: {\"type\": \"end\"}\n\n"
                print("--- [STREAM FINISHED] Final state sent to frontend ---")

        except Exception as e:
            error_data = {"type": "error", "message": str(e)}
            yield f"data: {json.dumps(error_data)}\n\n"

    return StreamingResponse(event_generator(), media_type="text/event-stream")

# Mount the frontend build directory
build_path = os.path.join(os.getcwd(), "build")

if os.path.exists(build_path):
    # 1. Mount /static for JS, CSS, and hashed images (like blbg4.png)
    app.mount("/static", StaticFiles(directory=os.path.join(build_path, "static")), name="static")

    # 2. IMPORTANT: Mount the images directory explicitly if it exists in your build
    # This fixes the missing patterns in your SVG (imgNormal/imgHover)
    images_path = os.path.join(build_path, "images")
    if os.path.exists(images_path):
        app.mount("/images", StaticFiles(directory=images_path), name="images")

    @app.get("/{catchall:path}")
    async def read_index(catchall: str):
        # Serve any specific file from the build root (favicon, etc.)
        file_path = os.path.join(build_path, catchall)
        if os.path.isfile(file_path):
            return FileResponse(file_path)
        
        # Fallback to index.html for React SPA
        return FileResponse(os.path.join(build_path, "index.html"))